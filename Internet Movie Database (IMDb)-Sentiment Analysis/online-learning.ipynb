{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4469a831",
   "metadata": {},
   "source": [
    "# Out-of-core Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b918b53",
   "metadata": {},
   "source": [
    "In real-world applications, it is not uncommon to have datasets bigger than the memory of the computer. So we need newer algorithms to train the model in batches of data that we have. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "09bc765f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\"I went and saw this movie last night after being coaxed to by a few friends of mine. I\\'ll admit that I was reluctant to see it because from what I knew of Ashton Kutcher he was only able to do comedy. I was wrong. Kutcher played the character of Jake Fischer very well, and Kevin Costner played Ben Randall with such professionalism. The sign of a good movie is that it can toy with our emotions. This one did exactly that. The entire theater (which was sold out) was overcome by laughter during the first half of the movie, and were moved to tears during the second half. While exiting the theater I not only saw many women in tears, but many full grown men as well, trying desperately not to let anyone see them crying. This movie was great, and I suggest that you go see it before you judge.\"', 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "# A tokenizer to clean and split text\n",
    "def tokenizer(text):\n",
    "    text = re.sub(r'<[^>]*>', '', text)\n",
    "    emoticons = re.findall(r'(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text.lower())\n",
    "    text = re.sub(r'[\\W]+', ' ', text.lower()) + ' '.join(emoticons).replace('-', '')\n",
    "    tokenized = [w for w in text.split() if w not in stop]\n",
    "    return tokenized\n",
    "\n",
    "\n",
    "# Function to stream documents one at a time\n",
    "def stream_docs(path):\n",
    "    with open(path, 'r', encoding='utf-8') as csv:\n",
    "        next(csv)\n",
    "        for line in csv:\n",
    "            text, label = line[:-3], int(line[-2])\n",
    "            yield text, label\n",
    "\n",
    "\n",
    "print(next(stream_docs('imdb_reviews.csv')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ccdd3b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "# Read all data once\n",
    "\n",
    "df = pd.read_csv(\"imdb_reviews.csv\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['review'], df['sentiment'], test_size=0.1, random_state=42\n",
    ")\n",
    "train_df = pd.DataFrame({\"review\": X_train, \"sentiment\": y_train})\n",
    "test_df = pd.DataFrame({\"review\": X_test, \"sentiment\": y_test})\n",
    "\n",
    "train_df.to_csv(\"imdb_reviews_train.csv\", index=False, encoding=\"utf-8\")\n",
    "test_df.to_csv(\"imdb_reviews_test.csv\", index=False, encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "986661a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_minibatch(doc_stream, size):\n",
    "    docs, y = [] , []\n",
    "    try: \n",
    "        for _ in range(size):\n",
    "            text, label = next(doc_stream)\n",
    "            docs.append(text)\n",
    "            y.append(label)\n",
    "    except StopIteration:\n",
    "        return None, None\n",
    "    return docs, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "45004b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "vect = HashingVectorizer(decode_error='ignore',\n",
    "                         n_features=2**21,\n",
    "                         preprocessor=None,\n",
    "                         tokenizer=tokenizer)\n",
    "clf = SGDClassifier(loss='log_loss',random_state=42)\n",
    "doc_stream = stream_docs(path='imdb_reviews_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7400fde4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:28\n"
     ]
    }
   ],
   "source": [
    "import pyprind \n",
    "pbar = pyprind.ProgBar(45)\n",
    "classes = np.array([0,1])\n",
    "for _ in range(45):\n",
    "    X_train, y_train = get_minibatch(doc_stream,size=1000)\n",
    "    if not X_train:\n",
    "        break\n",
    "    X_train = vect.transform(X_train)\n",
    "    clf.partial_fit(X_train, y_train, classes=classes)\n",
    "    pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5c6f9e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.874\n"
     ]
    }
   ],
   "source": [
    "doc_stream_test = stream_docs(path='imdb_reviews_test.csv')\n",
    "X_test, y_test = get_minibatch(doc_stream_test, size=5000)\n",
    "X_test = vect.transform(X_test)\n",
    "print(f'Accuracy: {clf.score(X_test, y_test):.3f}') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2e9208",
   "metadata": {},
   "source": [
    "# Topic modeling with latent Dirichlet allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae1bc38",
   "metadata": {},
   "source": [
    "## Decomposing text documents with LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "87089f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I went and saw this movie last night after bei...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Actor turned director Bill Paxton follows up h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As a recreational golfer with some knowledge o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I saw this film in a sneak preview, and it is ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bill Paxton has taken the true story of the 19...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>Towards the end of the movie, I felt it was to...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>This is the kind of movie that my enemies cont...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I saw 'Descent' last night at the Stockholm Fi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>Some films that you pick up for a pound turn o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>This is one of the dumbest films, I've ever se...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment\n",
       "0      I went and saw this movie last night after bei...          1\n",
       "1      Actor turned director Bill Paxton follows up h...          1\n",
       "2      As a recreational golfer with some knowledge o...          1\n",
       "3      I saw this film in a sneak preview, and it is ...          1\n",
       "4      Bill Paxton has taken the true story of the 19...          1\n",
       "...                                                  ...        ...\n",
       "49995  Towards the end of the movie, I felt it was to...          0\n",
       "49996  This is the kind of movie that my enemies cont...          0\n",
       "49997  I saw 'Descent' last night at the Stockholm Fi...          0\n",
       "49998  Some films that you pick up for a pound turn o...          0\n",
       "49999  This is one of the dumbest films, I've ever se...          0\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('imdb_reviews.csv' , encoding='utf-8')\n",
    "df.rename(columns={\"0\": \"review\" ,  \"1\": \"sentiment\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "59fbd86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_df andd max_features are 2 hyperparameters to tune. \n",
    "# first one is a threshold for the data so if the word is occured too frequlently in the doc, it will be excluded\n",
    "# Second one is to limit the max_features umberr of the words that are more frequent. \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count = CountVectorizer(stop_words='english',\n",
    "                        max_df=.1,\n",
    "                        max_features=5000)\n",
    "X = count.fit_transform(df['review'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "745ba0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "lda = LatentDirichletAllocation(n_components=10,\n",
    "                                random_state=123,\n",
    "                                learning_method='batch')\n",
    "\n",
    "X_topics = lda.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "572f69d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 5000)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now in lda we have 10 cclsters of words ech with 5000 word frequencies that shows which words are more frequent in each cluster. \n",
    "lda.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe569e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1:\n",
      "horror effects budget special gore\n",
      "Topic 2:\n",
      "guy money worst minutes girl\n",
      "Topic 3:\n",
      "version action english japanese match\n",
      "Topic 4:\n",
      "book read game documentary feel\n",
      "Topic 5:\n",
      "series tv episode shows episodes\n",
      "Topic 6:\n",
      "family woman father mother wife\n",
      "Topic 7:\n",
      "music role performance musical star\n",
      "Topic 8:\n",
      "war police men murder action\n",
      "Topic 9:\n",
      "script comedy role actor performance\n",
      "Topic 10:\n",
      "comedy action original watched wasn\n"
     ]
    }
   ],
   "source": [
    "# number of top words to show per topic\n",
    "n_top_words = 5\n",
    "\n",
    "feature_names = count.get_feature_names_out()\n",
    "\n",
    "\n",
    "for topic_idx, topic in enumerate(lda.components_):\n",
    "    print(f\"Topic {topic_idx + 1}:\")\n",
    "    top_word_indices = topic.argsort()[-n_top_words:][::-1]\n",
    "    top_words = [feature_names[i] for i in top_word_indices]\n",
    "    print(\" \".join(top_words))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
